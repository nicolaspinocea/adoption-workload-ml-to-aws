# adoption-workload-ml-to-aws

A data scientist can develop a machine learning model using various open-source frameworks and tools, often without relying on a cloud-based development environment. However, as a project grows in both complexity and operational scope, challenges begin to emerge that go beyond the traditional skill set of a data scientist. These include scaling a solution for real-time consumption, ensuring interoperability between data services, and implementing proper monitoring and logging. When combined with the trend of moving applications to the cloud, the concept of ML-Ops becomes essential.

In this repository, we will walk through the step-by-step process of deploying a machine learning model—originally developed on-premise—into the cloud, culminating in the use of SageMaker Pipelines, a service that enables the orchestration of ML-Ops-oriented workflows within the AWS ecosystem. The topics covered in this repository:

[ ] Training a model in the cloud – Traditional approach

[ ] Training a model in the cloud – SageMaker approach

[ ] ML model lifecycle with SageMaker

[ ] From Data Scientist to MLOps – SageMaker Pipelines

